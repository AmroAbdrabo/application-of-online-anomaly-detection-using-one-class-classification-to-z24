{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incremental learning with River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import active\n",
    "from river import datasets\n",
    "import numpy as np\n",
    "from river import feature_extraction\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "import sys\n",
    "sys.path.append('.\\\\..\\\\..\\\\..\\\\Chapter2-Z24-dataset')\n",
    "from predict import binarize\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Accuracy: 86.60%"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from river import active\n",
    "from river import datasets\n",
    "import numpy as np\n",
    "from river import feature_extraction\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "import sys\n",
    "sys.path.append('.\\\\Chapter2-Z24-dataset')\n",
    "\n",
    "dataset = datasets.SMSSpam()\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "model = (\n",
    "    feature_extraction.TFIDF(on='body') |\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "model = active.EntropySampler(model, seed=42)\n",
    "\n",
    "n_samples_used = 0\n",
    "for x, y in dataset:\n",
    "    y_pred, ask = model.predict_one(x)\n",
    "    metric = metric.update(y, y_pred)\n",
    "    if ask:\n",
    "        n_samples_used += 1\n",
    "        model = model.learn_one(x, y)\n",
    "\n",
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'SMSSpam' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amroa\\Documents\\thesis\\Chapter3-ActiveLearning\\Streaming-AL\\River\\river_experiments.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/amroa/Documents/thesis/Chapter3-ActiveLearning/Streaming-AL/River/river_experiments.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(dataset)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/amroa/Documents/thesis/Chapter3-ActiveLearning/Streaming-AL/River/river_experiments.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dataset[\u001b[39m\"\u001b[39;49m\u001b[39mSamples\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'SMSSpam' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "x = np.array(dataset)\n",
    "dataset[\"Samples\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xi, yi in zip(X, y):\n",
    "    # This is where the model learns\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream\n",
    "\n",
    "for xi, yi in stream.iter_sklearn_dataset(datasets.load_breast_cancer()):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean radius': 7.76,\n",
       " 'mean texture': 24.54,\n",
       " 'mean perimeter': 47.92,\n",
       " 'mean area': 181.0,\n",
       " 'mean smoothness': 0.05263,\n",
       " 'mean compactness': 0.04362,\n",
       " 'mean concavity': 0.0,\n",
       " 'mean concave points': 0.0,\n",
       " 'mean symmetry': 0.1587,\n",
       " 'mean fractal dimension': 0.05884,\n",
       " 'radius error': 0.3857,\n",
       " 'texture error': 1.428,\n",
       " 'perimeter error': 2.548,\n",
       " 'area error': 19.15,\n",
       " 'smoothness error': 0.007189,\n",
       " 'compactness error': 0.00466,\n",
       " 'concavity error': 0.0,\n",
       " 'concave points error': 0.0,\n",
       " 'symmetry error': 0.02676,\n",
       " 'fractal dimension error': 0.002783,\n",
       " 'worst radius': 9.456,\n",
       " 'worst texture': 30.37,\n",
       " 'worst perimeter': 59.16,\n",
       " 'worst area': 268.6,\n",
       " 'worst smoothness': 0.08996,\n",
       " 'worst compactness': 0.06444,\n",
       " 'worst concavity': 0.0,\n",
       " 'worst concave points': 0.0,\n",
       " 'worst symmetry': 0.2871,\n",
       " 'worst fractal dimension': 0.07039}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.60%\n"
     ]
    }
   ],
   "source": [
    "from river import active\n",
    "from river import datasets\n",
    "import numpy as np\n",
    "from river import feature_extraction\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.SMSSpam()\n",
    "\n",
    "# Convert the dataset to numpy arrays\n",
    "data = [(x, y) for x, y in dataset]\n",
    "X = np.array([item[0]['body'] for item in data])\n",
    "y = np.array([item[1] for item in data])\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "model = (\n",
    "    feature_extraction.TFIDF() |\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "model = active.EntropySampler(model, seed=42)\n",
    "\n",
    "n_samples_used = 0\n",
    "for i in range(X.shape[0]):\n",
    "    x = X[i]\n",
    "    y_true = y[i]\n",
    "    y_pred, ask = model.predict_one(x)\n",
    "    metric = metric.update(y_true, y_pred)\n",
    "    if ask:\n",
    "        n_samples_used += 1\n",
    "        model = model.learn_one(x, y_true)\n",
    "\n",
    "print(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported type for data: <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\amroa\\Documents\\thesis\\Chapter3-ActiveLearning\\Streaming-AL\\River\\river_experiments.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amroa/Documents/thesis/Chapter3-ActiveLearning/Streaming-AL/River/river_experiments.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m x \u001b[39m=\u001b[39m X[i]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amroa/Documents/thesis/Chapter3-ActiveLearning/Streaming-AL/River/river_experiments.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m y_true \u001b[39m=\u001b[39m y[i]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/amroa/Documents/thesis/Chapter3-ActiveLearning/Streaming-AL/River/river_experiments.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m y_pred, ask \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict_one(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amroa/Documents/thesis/Chapter3-ActiveLearning/Streaming-AL/River/river_experiments.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m metric \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mupdate(y_true, y_pred)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/amroa/Documents/thesis/Chapter3-ActiveLearning/Streaming-AL/River/river_experiments.ipynb#X12sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m ask:\n",
      "File \u001b[1;32mc:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\river\\active\\base.py:67\u001b[0m, in \u001b[0;36mActiveLearningClassifier.predict_one\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_one\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     54\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict the label of `x` and indicate whether a label is needed.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m     y_pred, ask_for_label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba_one(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     68\u001b[0m     \u001b[39mif\u001b[39;00m y_pred:\n\u001b[0;32m     69\u001b[0m         y_pred \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(y_pred, key\u001b[39m=\u001b[39my_pred\u001b[39m.\u001b[39mget)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\river\\active\\base.py:50\u001b[0m, in \u001b[0;36mActiveLearningClassifier.predict_proba_one\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba_one\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     37\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Predict the probability of each label for `x` and indicate whether a label is needed.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclassifier\u001b[39m.\u001b[39;49mpredict_proba_one(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m y_pred, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ask_for_label(x, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\river\\linear_model\\log_reg.py:93\u001b[0m, in \u001b[0;36mLogisticRegression.predict_proba_one\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_proba_one\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 93\u001b[0m     p \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mmean_func(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_dot_one(x))  \u001b[39m# Convert logit to probability\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m {\u001b[39mFalse\u001b[39;00m: \u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m p, \u001b[39mTrue\u001b[39;00m: p}\n",
      "File \u001b[1;32mc:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\river\\linear_model\\base.py:147\u001b[0m, in \u001b[0;36mGLM._raw_dot_one\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raw_dot_one\u001b[39m(\u001b[39mself\u001b[39m, x: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m--> 147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights \u001b[39m@\u001b[39m utils\u001b[39m.\u001b[39;49mVectorDict(x) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept\n",
      "File \u001b[1;32mc:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\river\\utils\\vectordict.pyx:124\u001b[0m, in \u001b[0;36mriver.utils.vectordict.VectorDict.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unsupported type for data: <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "from river import active\n",
    "from river import datasets\n",
    "import numpy as np\n",
    "from river import feature_extraction\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.SMSSpam()\n",
    "\n",
    "# Convert the dataset to numpy arrays\n",
    "data = [(x, y) for x, y in dataset]\n",
    "X = iris['data']#np.array([item[0]['body'] for item in data])\n",
    "y = iris['target'] #np.array([item[1] for item in data])\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "model = (\n",
    "    \n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "model = active.EntropySampler(model, seed=42)\n",
    "\n",
    "n_samples_used = 0\n",
    "for i in range(X.shape[0]):\n",
    "    x = X[i]\n",
    "    y_true = y[i]\n",
    "    y_pred, ask = model.predict_one(x)\n",
    "    metric = metric.update(y_true, y_pred)\n",
    "    if ask:\n",
    "        n_samples_used += 1\n",
    "        model = model.learn_one(x, y_true)\n",
    "\n",
    "print(metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 44.00%\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from river import active\n",
    "from river import datasets as river_datasets\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "\n",
    "# Load the iris dataset from sklearn\n",
    "sklearn_iris = datasets.load_iris()\n",
    "X_np = sklearn_iris['data']\n",
    "y_np = sklearn_iris['target']\n",
    "\n",
    "# Convert the numpy arrays to a list of dictionaries\n",
    "X = [{\"feature_\" + str(j): X_np[i][j] for j in range(X_np.shape[1])} for i in range(X_np.shape[0])]\n",
    "\n",
    "# Initialize model and metric\n",
    "metric = metrics.Accuracy()\n",
    "model = linear_model.LogisticRegression()\n",
    "model = active.EntropySampler(model, seed=42)\n",
    "\n",
    "n_samples_used = 0\n",
    "for x, y_true in zip(X, y_np):\n",
    "    y_pred, ask = model.predict_one(x)\n",
    "    metric = metric.update(y_true, y_pred)\n",
    "    if ask:\n",
    "        n_samples_used += 1\n",
    "        model = model.learn_one(x, y_true)\n",
    "\n",
    "print(metric)\n",
    "print(n_samples_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "Accuracy: 44.00%\n",
      "Number of samples used for learning: 41\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets as skdatasets  # Import to avoid naming conflicts\n",
    "from river import active\n",
    "from river import datasets\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "\n",
    "# Load the iris dataset from sklearn\n",
    "iris_sk = skdatasets.load_iris()\n",
    "\n",
    "# Prepare the data in a format compatible with river\n",
    "X_river = [\n",
    "    {f\"feature_{i}\": value for i, value in enumerate(sample)}\n",
    "    for sample in iris_sk['data']\n",
    "]\n",
    "y_river = iris_sk['target'].tolist()  # Converting to list for easier iteration\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "base_model = linear_model.LogisticRegression()\n",
    "model = active.EntropySampler(base_model, seed=42)\n",
    "\n",
    "n_samples_used = 0\n",
    "\n",
    "# Process each sample in the dataset\n",
    "for i in range(len(X_river)):\n",
    "    x = X_river[i]\n",
    "    y_true = y_river[i]\n",
    "    y_pred, ask = model.predict_one(x)  # x is now a dictionary\n",
    "    metric = metric.update(y_true, y_pred)\n",
    "\n",
    "    if ask:\n",
    "        n_samples_used += 1\n",
    "        model = model.learn_one(x, y_true)  # Learn from the true label\n",
    "\n",
    "print(metric)\n",
    "print(f\"Number of samples used for learning: {n_samples_used}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Load the iris dataset\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# 2. Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Train a logistic regression model\n",
    "clf = LogisticRegression()  # Setting a high max_iter to ensure convergence\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model's performance on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\X_train.npy\")\n",
    "labels_train = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\labels_train.npy\")\n",
    "X_test = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\X_test.npy\")\n",
    "labels_test = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((544, 906), (68, 906))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, \\\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "features_to_keep = 79\n",
    "neighbors = 41\n",
    "\n",
    "y_train = binarize(labels_train)\n",
    "log_reg = LogisticRegression(C = 12.5) \n",
    "y_train = binarize(labels_train)\n",
    "log_reg.fit(X_train, y)\n",
    "sorted_feature_indices = np.argsort(log_reg.coef_[0])[::-1] # get the indices of the most important features in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction (to stabilize KNN and avoid dimensionality curse)\n",
    "indices = sorted_feature_indices[:features_to_keep]\n",
    "X_train_top_feats = X_train[:, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.06%\n",
      "Number of samples used for learning: 188\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets as skdatasets  # Import to avoid naming conflicts\n",
    "from river import active\n",
    "from river import datasets\n",
    "from river import linear_model\n",
    "from river import metrics\n",
    "\n",
    "# Prepare the data in a format compatible with river\n",
    "X_river = [\n",
    "    {f\"feature_{i}\": value for i, value in enumerate(sample)}\n",
    "    for sample in X_train_top_feats\n",
    "]\n",
    "y_river = y_train.tolist()  # Converting to list for easier iteration\n",
    "\n",
    "metric = metrics.Accuracy()\n",
    "base_model = linear_model.LogisticRegression()\n",
    "model = active.EntropySampler(base_model, seed=42)\n",
    "\n",
    "n_samples_used = 0\n",
    "\n",
    "# Process each sample in the dataset\n",
    "for i in range(len(X_river)):\n",
    "    x = X_river[i]\n",
    "    y_true = y_river[i]\n",
    "    y_pred, ask = model.predict_one(x)  # x is now a dictionary\n",
    "    metric = metric.update(y_true, y_pred)\n",
    "\n",
    "    if ask:\n",
    "        n_samples_used += 1\n",
    "        model = model.learn_one(x, y_true)  # Learn from the true label\n",
    "\n",
    "print(metric)\n",
    "print(f\"Number of samples used for learning: {n_samples_used}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_river_test = [\n",
    "    {f\"feature_{i}\": value for i, value in enumerate(sample)}\n",
    "    for sample in X_train_top_feats\n",
    "]\n",
    "y_river = y_train.tolist()  # Converting to list for easier iteration\n",
    "\n",
    "\n",
    "# Process each sample in the dataset\n",
    "for i in range(len(X_river)):\n",
    "    x = X_river[i]\n",
    "    y_true = y_river[i]\n",
    "    y_pred, ask = model.predict_one(x)  # x is now a dictionary\n",
    "    metric = metric.update(y_true, y_pred)\n",
    "\n",
    "    if ask:\n",
    "        n_samples_used += 1\n",
    "        model = model.learn_one(x, y_true)  # Learn from the true label\n",
    "\n",
    "print(metric)\n",
    "print(f\"Number of samples used for learning: {n_samples_used}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
