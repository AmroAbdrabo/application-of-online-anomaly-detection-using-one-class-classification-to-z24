{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCC solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sys\n",
    "sys.path.append('.\\\\..\\\\..\\\\Chapter2-Z24-dataset')\n",
    "from predict import binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\X_train.npy\")\n",
    "labels_train = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\labels_train.npy\")\n",
    "X_test = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\X_test.npy\")\n",
    "labels_test = np.load(\"C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\labels_test.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544\n"
     ]
    }
   ],
   "source": [
    "# extract the relevant file indices for training and testing separately\n",
    "test_indices=  np.array([])\n",
    "train_indices=  np.array([])\n",
    "\n",
    "for i in range(17):\n",
    "    random.seed(i)\n",
    "    nbr_splits = 36 #  recall 612/17 = 36, where 612 = total nbr of epochs, 17 is nbr of scenarios\n",
    "    test_split = 4\n",
    "    test_indices_temp = np.array(random.sample(range(nbr_splits), test_split))\n",
    "    test_indices = np.append(test_indices, i*nbr_splits + test_indices_temp)\n",
    "    train_indices = np.append(train_indices,  i*nbr_splits+ np.array([x for x in range(nbr_splits) if x not in test_indices_temp]))\n",
    "\n",
    "print(len(train_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ctr = 0\n",
    "test_ctr = 0\n",
    "data_all = []\n",
    "labels_all = []\n",
    "for i in range(612):\n",
    "    if i in train_indices:\n",
    "        data_all.append(X_train[train_ctr])\n",
    "        labels_all.append(labels_train[train_ctr])\n",
    "        train_ctr += 1\n",
    "    elif i in test_indices:\n",
    "        data_all.append(X_test[test_ctr])\n",
    "        labels_all.append(labels_test[test_ctr])\n",
    "        test_ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = binarize(labels_all) # is the labels of all instances \n",
    "data_all = np.array(data_all) # are all the instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters and data\n",
    "features_to_keep = 79\n",
    "neighbors = 41\n",
    "y_train = binarize(labels_all)\n",
    "log_reg = LogisticRegression(C = 12.5) \n",
    "y_train = binarize(labels_train)\n",
    "log_reg.fit(X_train, y_train)\n",
    "sorted_feature_indices = np.argsort(log_reg.coef_[0])[::-1] # get the indices of the most important features in descending order\n",
    "indices = sorted_feature_indices[:features_to_keep]\n",
    "data_all_top = data_all[:, indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(healthy_data, test_size, validation_size):\n",
    "    # Split data into training and testing\n",
    "    healthy_train, healthy_test = train_test_split(healthy_data, test_size=test_size, random_state=42)\n",
    "    # Split training data further to get a validation set\n",
    "    healthy_train, healthy_validation = train_test_split(healthy_train, test_size=validation_size, random_state=42)\n",
    "    \n",
    "    return healthy_train, healthy_validation, healthy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, healthy_data, unhealthy_validation, unhealthy_test, train_split, tune=False):\n",
    "    window = int(train_split*healthy_data.shape[0])\n",
    "    print(f\"Using {window} instances\")\n",
    "    model.fit(healthy_data[-window:])\n",
    "    \n",
    "    # predict on validation and test data (damaged)\n",
    "    preds_validation = model.predict(unhealthy_validation)\n",
    "    preds_test = model.predict(unhealthy_test)\n",
    "    \n",
    "    # occ models are unsupervised, they predict +1 for inliers and -1 for outliers\n",
    "    # invert the predictions because in our case, healthy is 0 and unhealthy is 1\n",
    "    preds_validation = (preds_validation == -1).astype(int)\n",
    "    preds_test = (preds_test == -1).astype(int)\n",
    "\n",
    "    # labels for validation and test sets (since we know they should be 1 for unhealthy)\n",
    "    unhealthy_validation_labels = np.ones(len(unhealthy_validation))\n",
    "    unhealthy_test_labels = np.ones(len(unhealthy_test))\n",
    "    \n",
    "    # evaluate model\n",
    "    print(\"Validation Results:\")\n",
    "    print(classification_report(unhealthy_validation_labels, preds_validation))\n",
    "    print(\"Accuracy:\", accuracy_score(unhealthy_validation_labels, preds_validation))\n",
    "    \n",
    "    print(\"Test Results:\")\n",
    "    print(classification_report(unhealthy_test_labels, preds_test))\n",
    "    print(\"Accuracy:\", accuracy_score(unhealthy_test_labels, preds_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into healthy and unhealthy instances\n",
    "healthy_data = data_all_top[y_all == 0]\n",
    "unhealthy_data = data_all_top[y_all == 1]\n",
    "\n",
    "unhealthy_validation, unhealthy_test = train_test_split(\n",
    "    unhealthy_data, test_size=0.8, random_state=42\n",
    ")\n",
    "\n",
    "# crwate models\n",
    "svm_model = OneClassSVM(kernel='linear', gamma='auto')\n",
    "isolation_forest = IsolationForest(n_estimators=100, contamination='auto', random_state=42)\n",
    "lof_model = LocalOutlierFactor(n_neighbors=20, novelty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((288, 79), (324, 79))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_data.shape, unhealthy_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating One-Class SVM...\n",
      "Using 14 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 43 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00         0\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       0.50      0.50      0.50       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 0.9961538461538462\n",
      "Using 72 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 100 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 129 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 158 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 187 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 216 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 244 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n",
      "Using 273 instances\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        64\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "Accuracy: 1.0\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00       260\n",
      "\n",
      "    accuracy                           1.00       260\n",
      "   macro avg       1.00      1.00      1.00       260\n",
      "weighted avg       1.00      1.00      1.00       260\n",
      "\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\amroa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate all\n",
    "print(\"Evaluating One-Class SVM...\")\n",
    "for el in np.arange(0.05, 1.0, 0.1):\n",
    "    evaluate_model(svm_model, healthy_data, unhealthy_validation, unhealthy_test, el)\n",
    "\n",
    "#print(\"\\nEvaluating Isolation Forest...\")\n",
    "#evaluate_model(isolation_forest, healthy_data, unhealthy_validation, unhealthy_test)\n",
    "\n",
    "#print(\"\\nEvaluating Local Outlier Factor...\")\n",
    "#evaluate_model(lof_model, healthy_data, unhealthy_validation, unhealthy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "       429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "       442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "       455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "       468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "       481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "       494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "       507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519,\n",
       "       520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532,\n",
       "       533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545,\n",
       "       546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558,\n",
       "       559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571,\n",
       "       572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584,\n",
       "       585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
       "       598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610,\n",
       "       611])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(np.hstack((test_indices, train_indices))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
