{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## technically this should have been done berfore imputation and scaling but I realized the test data was too little. We will keep test at 10% since the data is very little\n",
    "def redistribute_data(X_train, labels_train, X_test, labels_test, test_split):\n",
    "    \"\"\" \n",
    "    This method re-distributes more data into the testing set\n",
    "    \"\"\"\n",
    "    import math\n",
    "    tot_data = len(labels_train) + len(labels_test)\n",
    "    cur_split = len(labels_test)/tot_data\n",
    "    if test_split <= cur_split:\n",
    "        return X_train, labels_train, X_test, labels_test # we don't handle the case where we want to reduce the amount of test data\n",
    "    else:\n",
    "        indices_to_sample = np.linspace(0,  len(labels_train) - 1, int( math.ceil((test_split - cur_split)*tot_data ))).astype(int) # get (test_split - cur_split)*tot_data indices in the range of 0 to len(labels_train) - 1 (both inclusive) \n",
    "\n",
    "        for el in indices_to_sample:\n",
    "            \n",
    "            # get training data at index el\n",
    "            cur_row = X_train[el]\n",
    "            cur_label = labels_train[el]\n",
    "\n",
    "            # add them to the test cases\n",
    "            X_test = np.append(X_test, cur_row.reshape(1, X_train.shape[1]), axis = 0)\n",
    "            labels_test = np.append(labels_test, cur_label)\n",
    "            \n",
    "        # remove them from the train cases\n",
    "        X_train = np.delete(X_train, indices_to_sample, axis=0)\n",
    "        labels_train = np.delete(labels_train, indices_to_sample, axis = 0)\n",
    "\n",
    "        return X_train, labels_train, X_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the precomputed arrays \n",
    "train_features_np = np.load(\"train_shape_595_5_49.npy\")\n",
    "test_features_np = np.load(\"test_shape_17_5_49.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_flattened = np.array([el.flatten() for el in train_features_np]) \n",
    "test_flattened = np.array([el.flatten() for el in test_features_np])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def kmeans(pca_param)\n",
    "pca = PCA(n_components=2) \n",
    "X_train_2D = pca.fit_transform(X_train)\n",
    "\n",
    "def optimal_clusters(data, max_k):\n",
    "    iters = range(2, max_k+1, 1)\n",
    "\n",
    "    s = []\n",
    "\n",
    "    for k in iters:\n",
    "        clusterer = KMeans(n_clusters=k, n_init='auto', random_state=10)\n",
    "        clusterer_labels = clusterer.fit_predict(data)\n",
    "        s.append(silhouette_score(data, clusterer_labels))\n",
    "\n",
    "    return iters, s\n",
    "\n",
    "# Determine the optimal number of clusters\n",
    "iters, silhouette_scores = optimal_clusters(X_train_2D, 20)\n",
    "optimal_k = iters[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(iters, silhouette_scores, '-o', color='blue')\n",
    "plt.title('Silhouette Scores vs Number of Clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xticks(iters)\n",
    "plt.show()\n",
    "\n",
    "# Perform KMeans with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, n_init='auto', random_state=10)\n",
    "clusters = kmeans.fit_predict(X_train_2D)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.scatter(X_train_2D[:,0], X_train_2D[:,1], c=clusters, cmap='rainbow', edgecolor='k', s=100)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=300, c='black', marker='X')\n",
    "plt.title(f\"K-means Clustering with {optimal_k} clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "def kmeans(pca_param)\n",
    "pca = PCA(n_components=2) \n",
    "X_train_2D = pca.fit_transform(X_train)\n",
    "\n",
    "def optimal_clusters(data, max_k):\n",
    "    iters = range(2, max_k+1, 1)\n",
    "\n",
    "    s = []\n",
    "\n",
    "    for k in iters:\n",
    "        clusterer = KMeans(n_clusters=k, n_init='auto', random_state=10)\n",
    "        clusterer_labels = clusterer.fit_predict(data)\n",
    "        s.append(silhouette_score(data, clusterer_labels))\n",
    "\n",
    "    return iters, s\n",
    "\n",
    "# Determine the optimal number of clusters\n",
    "iters, silhouette_scores = optimal_clusters(X_train_2D, 20)\n",
    "optimal_k = iters[silhouette_scores.index(max(silhouette_scores))]\n",
    "print(f\"Optimal number of clusters: {optimal_k}\")\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(iters, silhouette_scores, '-o', color='blue')\n",
    "plt.title('Silhouette Scores vs Number of Clusters')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.xticks(iters)\n",
    "plt.show()\n",
    "\n",
    "# Perform KMeans with the optimal number of clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, n_init='auto', random_state=10)\n",
    "clusters = kmeans.fit_predict(X_train_2D)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.scatter(X_train_2D[:,0], X_train_2D[:,1], c=clusters, cmap='rainbow', edgecolor='k', s=100)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=300, c='black', marker='X')\n",
    "plt.title(f\"K-means Clustering with {optimal_k} clusters\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
