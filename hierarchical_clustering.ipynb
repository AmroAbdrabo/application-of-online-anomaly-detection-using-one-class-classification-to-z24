{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82a13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from random import choices, sample\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1081ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_cluster(X, max_clusters=None):\n",
    "    \"\"\"\n",
    "    Builds a hierarchical clustering using the linkage function from scipy \n",
    "    (agglomerative clustering using ward's linkage and euclidean distance).\n",
    "    Records clusters as they merge; output clusters start at the root node.\n",
    "    The two child nodes, associated with each new node, are recorded for reference.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): [N x d] matrix, containing N observations of d-dimensional input data\n",
    "        max_clusters (int, optional): Determines the maximum number of clusters defined. \n",
    "            Default value (N-1) considers clusters down to single observations.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing N-1 arrays, each represents a node in the hierarchical tree,\n",
    "            containing the data indices associated with each cluster.\n",
    "        np.ndarray: A [2 x N-1] matrix, containing the 2 child nodes for each cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    if max_clusters is None:\n",
    "        max_clusters = len(X) - 1\n",
    "\n",
    "    # Build hierarchical tree\n",
    "    Z = linkage(X, method='ward', metric='euclidean')\n",
    "\n",
    "    N = len(X)\n",
    "    u = [None] * (N - 1)\n",
    "    ch = np.zeros((2, N - 1), dtype=int)\n",
    "\n",
    "    # Using the output of linkage (Z) to build clusters\n",
    "    for m in range(len(u)):\n",
    "        # Join parts p1 & p2 of the clustering together using Z info\n",
    "        if Z[m, 0] < N:\n",
    "            p1 = [Z[m, 0]]\n",
    "            c1 = int(p1[0])\n",
    "        else:\n",
    "            p1 = u[int(Z[m, 0] - N)]\n",
    "            c1 = 2 * N - int(Z[m, 0])\n",
    "\n",
    "        if Z[m, 1] < N:\n",
    "            p2 = [Z[m, 1]]\n",
    "            c2 = int(p2[0])\n",
    "        else:\n",
    "            p2 = u[int(Z[m, 1] - N)]\n",
    "            c2 = 2 * N - int(Z[m, 1])\n",
    "     \n",
    "        u[m] = p1 + p2\n",
    "        ch[:, m] = [c1, c2]\n",
    "\n",
    "    u = list(reversed(u[:max_clusters]))\n",
    "    u_= [[int(x) for x in sublist] for sublist in u]\n",
    "    u = [x for x in u_ if x]\n",
    "\n",
    "    ch = np.fliplr(ch[:, :max_clusters])\n",
    "    ch = ch.astype(int)\n",
    "    \n",
    "    return u, ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5de25ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_label(P, u, Au, Lu, ch, z, N, eu, wu):\n",
    "    \"\"\"\n",
    "    Function to refine the pruning (P) and labelling (L) for the DH active learner.\n",
    "    \n",
    "    Parameters:\n",
    "    - P : list\n",
    "        Input pruning, to be refined (array of node/cluster numbers).\n",
    "    - u : dict\n",
    "        Contains N-1 arrays. Each array represents a node in the hierarchical tree.\n",
    "    - Au : list\n",
    "        Logistic array, indicating the admissibility of each cluster in the current pruning.\n",
    "    - Lu : dict\n",
    "        Cell containing the majority label(s), for each node.\n",
    "    - ch : numpy array\n",
    "        2x(N-1) matrix containing the 2 children nodes for each cluster.\n",
    "    - z : numpy array\n",
    "        Sampled data information array.\n",
    "    - N : int\n",
    "        Total number of clusters.\n",
    "    - eu : list\n",
    "        Error associated with propagating the majority label to unlabelled instances.\n",
    "    - wu : list\n",
    "        Node weights - proportion of the total data in each node.\n",
    "        \n",
    "    Returns:\n",
    "    - P_ : list\n",
    "        Output (refined) pruning.\n",
    "    - L : list\n",
    "        The majority label for each cluster in the refined pruning.\n",
    "    - XL : numpy array\n",
    "        The labelled dataset provided by the DH learner.\n",
    "    \"\"\"\n",
    "    \n",
    "    L = [0] * len(u)  # Initialize admissible cluster label pairs\n",
    "    P_ = list(P)  # Define working pruning\n",
    "\n",
    "    for i, v in enumerate(P):  # For each node in the current pruning\n",
    "        # LABEL parent node in case descendants are not admissible\n",
    "        Lu[1] = 0  # Arbitrary label of root\n",
    "        if len(P) != 1 and len(Lu[v]) == 1:\n",
    "            L[v - 1] = Lu[v]\n",
    "\n",
    "        # Identify first descendants...\n",
    "        chv = ch[:, v - 1]\n",
    "        Pv = [v]\n",
    "        Achv = [Au[x - 1] for x in chv]\n",
    "\n",
    "        # While at least one pair of siblings is admissible, refine and label Pv\n",
    "        while np.sum(np.sum(Achv) == 2) >= 1:\n",
    "            i_ch = [idx for idx, val in enumerate(Achv) if np.sum(val) == 2]\n",
    "\n",
    "            for ich in i_ch:\n",
    "                ep = eu[Pv[ich] - 1]\n",
    "                ech = (1 / np.sum([wu[x - 1] for x in chv[:, ich]])) * np.sum(\n",
    "                    [wu[x - 1] * eu[x - 1] for x in chv[:, ich]])\n",
    "                Lch = [Lu[x] for x in chv[:, ich]]\n",
    "                Lch_log = [len(x) == 1 for x in Lch]\n",
    "\n",
    "                if len(Lu[Pv[ich]]) == 1 and ech < ep and np.sum(Lch_log) == 2:\n",
    "                    Pv[ich] = 0\n",
    "                    u_ = chv[:, ich]\n",
    "                    Pv.extend(list(u_))\n",
    "\n",
    "            Pv = [x for x in Pv if x != 0]\n",
    "\n",
    "            if len(set(Pv)) > chv.shape[1]:\n",
    "                chv = ch[:, [x - 1 for x in Pv]]\n",
    "                Achv = [Au[x - 1] for x in chv.flatten()]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if len(Pv) > 1:\n",
    "            print(f\"\\nTOTAL CLUSTERS {len(P_)}: nodes {Pv} replace node [{v}]\")\n",
    "            P_ = [x for x in P_ if x != v]\n",
    "            P_.extend(Pv)\n",
    "            for uw in Pv:\n",
    "                L[uw - 1] = Lu[uw]\n",
    "\n",
    "    xl = [0] * N\n",
    "    for idx, v in enumerate(P):\n",
    "        if len(P) >= len(set(z[:, -1])):\n",
    "            xi = u[v]\n",
    "            xl[xi[0]] = L[v - 1]\n",
    "\n",
    "    for idx in range(z.shape[0]):\n",
    "        z_ = int(z[idx, 0])\n",
    "        zl = z[idx, -1]\n",
    "        xl[z_ - 1] = zl\n",
    "\n",
    "    XL = np.array([[idx + 1, x] for idx, x in enumerate(xl) if x != 0])\n",
    "\n",
    "    return P_, L, XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1a00940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DH_AL(u, ch, B, T, y):\n",
    "    # Initialize variables\n",
    "    N = len(u[0])\n",
    "    Nu = [len(ue) for ue in u]\n",
    "    wu = np.array(Nu) / N\n",
    "    \n",
    "    z = []\n",
    "    uz = [ [] for _ in range(N-1)]\n",
    "    u_ = u.copy()\n",
    "    print(\"u is as: \")\n",
    "    print(u_)\n",
    "    \n",
    "    pl = [None] * len(u)\n",
    "    Aul = [None] * len(u)\n",
    "    Au = np.zeros(len(u) + N)\n",
    "    eu = np.ones(len(u) + N)\n",
    "    Lu = [None] * len(u)\n",
    "    \n",
    "    P = [0]\n",
    "    \n",
    "    for t in range(1, T+1):\n",
    "        for b in range(1, B+1):\n",
    "            # Select v from P\n",
    "            prop = wu[P]\n",
    "            for i, v in enumerate(P):\n",
    "                coeff = 1 if len(P) == 1 else 0 if not u_[v] else 1 - max(pl[v][:, -2])\n",
    "                prop[i] *= coeff\n",
    "            \n",
    "            prob = prop / np.sum(prop)\n",
    "            vi = choices(range(len(prob)), prob)[0]\n",
    "            \n",
    "            # Query label\n",
    "            print(\"P[vi] is \")\n",
    "            print(P[vi])\n",
    "            print(\"and u_ at that value is \")\n",
    "            print(u_[P[vi]])\n",
    "            print(\"vi is \")\n",
    "            print(vi)\n",
    "            print(\"P is \")\n",
    "            print(P)\n",
    "            s = 0\n",
    "            if len(u_[P[vi]]) != 0:\n",
    "                s = int(sample(u_[P[vi]], 1)[0])\n",
    "            else:\n",
    "                continue\n",
    "            for ui in u_:\n",
    "                if s in ui:\n",
    "                    ui.remove(s)\n",
    "            \n",
    "            print(\"s:\", s, \"Type of s:\", type(s))  # Debug: check what s holds\n",
    "            l = y[s]\n",
    "            z.append((s, P[vi], l))\n",
    "            \n",
    "            # Update node counts\n",
    "            u_i = [i for i, ue in enumerate(u) if s in ue]\n",
    "            for uw in u_i:\n",
    "                uz[uw].append((s, l))\n",
    "                nu = len(uz[uw])\n",
    "                \n",
    "                cl, c = zip(*Counter([l for s, l in uz[uw]]).items())\n",
    "                p_l = np.array(c) / nu\n",
    "                \n",
    "                delta = 1 / nu + np.sqrt((p_l * (1 - p_l)) / nu)\n",
    "                lb = np.maximum(p_l - delta, 0)\n",
    "                ub = np.minimum(p_l + delta, 1)\n",
    "                \n",
    "                pl[uw] = np.column_stack((cl, p_l, lb, ub))\n",
    "                Lu[uw] = cl[np.argmax(p_l)]\n",
    "                \n",
    "        # Update admissibilities, error/scores\n",
    "        u_i = [i for i, ple in enumerate(pl) if ple is not None]\n",
    "        for uw in u_i:\n",
    "            beta = 1.5\n",
    "            p_l = pl[uw]\n",
    "            if len(uz[uw]) > 1:\n",
    "                LHS = p_l[:, -2]\n",
    "                RHS = beta * p_l[:, -1] - 1\n",
    "                a_l = LHS[:, None] > RHS\n",
    "                \n",
    "                a_l[np.diag_indices_from(a_l)] = False\n",
    "                idx = np.all(a_l, axis=1)\n",
    "                \n",
    "                Aul[uw] = p_l[idx, 0]\n",
    "                Au[uw] = np.any(idx)\n",
    "                eu[uw] = 1 - np.max(p_l[:, 1]) if np.any(idx) else 1\n",
    "                \n",
    "        eu[Au == 0] = 1\n",
    "        \n",
    "        # Refine pruning & labelling\n",
    "        P, L, XL = prune_label(P, u, Au, Lu, ch, z, N, eu, wu)\n",
    "    \n",
    "    return XL, np.array(z), P, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7fe3de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexample run from https://github.com/labull/EngineeringPatternRecognition/tree/main/matlab/cluster_based_active_learning\\nn = 100;\\nB = 3; % batch size\\nt = n/3; % number of runs\\n\\n% run the DH learner\\n[xl, z] = DH_AL(u, ch, B, t, Y);\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "example run from https://github.com/labull/EngineeringPatternRecognition/tree/main/matlab/cluster_based_active_learning\n",
    "n = 100;\n",
    "B = 3; % batch size\n",
    "t = n/3; % number of runs\n",
    "\n",
    "% run the DH learner\n",
    "[xl, z] = DH_AL(u, ch, B, t, Y);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa508101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import fetch_signals\n",
    "from preprocess import preprocess\n",
    "from feature_extractor import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# gets X_train, y_train or X_test, y_test (pca and std should be None if train=True)\n",
    "def get_train_test(pca = None, scaler = None, train = True):  \n",
    "    print(\"benchmark 0\")  \n",
    "    signals, labels = fetch_signals('C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\data', train = train)\n",
    "    print(\"benchmark 1\")\n",
    "    preprocessed_sig = [preprocess(signal) for signal in signals]\n",
    "    print(\"benchmark 2\")\n",
    "\n",
    "    # extract the characteristics\n",
    "    X_train_time =  np.apply_along_axis(time_domain_characteristics, axis = 1, arr = preprocessed_sig) \n",
    "    print(\"benchmark 3\")\n",
    "    X_train_freq = np.apply_along_axis(frequency_domain_characteristics, axis = 1, arr = preprocessed_sig) \n",
    "    print(\"benchmark 4\")\n",
    "    Y = np.array(labels) - 1\n",
    "\n",
    "    # unstd stands for unstandardized\n",
    "    X_unstd = np.hstack((X_train_time, X_train_freq))\n",
    "    mask_finite = np.isfinite(X_unstd).all(axis=1)\n",
    "    X_unstd = X_unstd[mask_finite]\n",
    "    Y = Y[mask_finite]\n",
    "\n",
    "    # standardize the data and reduce dimensionality using PCA\n",
    "    if ((scaler  == None) or (pca == None)):\n",
    "        scaler = StandardScaler()\n",
    "        X_std = scaler.fit_transform(X_unstd)\n",
    "        pca = PCA(n_components=0.9, svd_solver = 'full') \n",
    "        X = pca.fit_transform(X_std)\n",
    "        return X, Y, pca, scaler\n",
    "    else:\n",
    "        X_std = scaler.transform(X_unstd)\n",
    "        X = pca.transform(X_std)\n",
    "        return X, Y, pca, scaler\n",
    "\n",
    "    return None, None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf3e05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark 0\n",
      "benchmark 1\n",
      "benchmark 2\n",
      "benchmark 3\n",
      "benchmark 4\n",
      "benchmark 0\n",
      "benchmark 1\n",
      "benchmark 2\n",
      "benchmark 3\n",
      "benchmark 4\n"
     ]
    }
   ],
   "source": [
    "X, Y, pca, scaler = get_train_test()\n",
    "x_test, y_test, _ , _ = get_train_test(pca = pca, scaler = scaler, train = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f46d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60718, 715)\n",
      "(60718,)\n"
     ]
    }
   ],
   "source": [
    "set(Y)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61839c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random sampling strategy (makes sure all *different* labels are included, plus whatever is needed to fill the algorithm run budget of t*B)\n",
    "def sample_indices_covering_all_Y_values(Y, N):\n",
    "    unique_values = np.unique(Y)\n",
    "    sampled_indices = []\n",
    "    \n",
    "    if N < len(unique_values):\n",
    "        raise ValueError(f\"N must be greater than or equal to the number of unique values in Y ({len(unique_values)}).\")\n",
    "        \n",
    "    for value in unique_values:\n",
    "        possible_indices = np.where(Y == value)[0]\n",
    "        sampled_index = np.random.choice(possible_indices)\n",
    "        sampled_indices.append(sampled_index)\n",
    "        \n",
    "    # calculate the remaining number of indices needed\n",
    "    remaining = N - len(unique_values)\n",
    "    \n",
    "    # exclude already sampled indices\n",
    "    all_indices = np.arange(len(Y))\n",
    "    remaining_indices = np.setdiff1d(all_indices, sampled_indices)\n",
    "    \n",
    "    # sample additional random indices to meet the required N\n",
    "    additional_indices = np.random.choice(remaining_indices, size=remaining, replace=False)\n",
    "    \n",
    "    # combine original sampled indices with the additional random indices\n",
    "    final_sampled_indices = np.concatenate([sampled_indices, additional_indices])\n",
    "    \n",
    "    return final_sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76d785fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUERY BUDGET ------ 20\n",
      "u is as: \n",
      "[[1942, 1989], [4055, 4103], [14034, 14082], [9295, 9343], [17735, 17783], [12992, 13040], [16145, 16193], [10879, 10927], [8775, 8823], [14044, 14092], [11413, 11461], [9612, 9644], [10882, 10930], [10881, 10929], [16154, 16202], [379, 426], [16499, 16546], [1950, 1997], [14048, 14096], [12459, 12507], [9821, 9869], [16157, 16205], [14049, 14097], [10876, 10924], [15088, 15136], [8242, 8290], [7195, 7243], [10015, 10031], [1952, 1999], [13509, 13556], [11402, 11450], [17207, 17255], [7199, 7247], [370, 417], [16484, 16516], [15098, 15146], [16149, 16197], [8238, 8286], [7200, 7248], [1943, 1990], [17200, 17247], [17731, 17779], [16670, 16718], [16669, 16717], [17727, 17775], [2525, 2477, 2461, 2541], [1947, 1994], [7197, 7245], [17206, 17253], [15090, 15138], [1949, 1996], [16678, 16726], [10158, 10190], [1946, 1993], [12462, 12510], [12983, 13031], [366, 413], [12454, 12502], [17201, 17248], [12993, 13041], [17197, 17244], [17729, 17777], [16611, 16627], [2065, 2080], [12463, 12511], [1941, 1988], [11406, 11454], [13520, 13568], [7202, 7250], [7198, 7246], [12468, 12516], [16672, 16720], [8252, 8300], [12466, 12514], [12464, 12512], [375, 422], [7204, 7252], [7193, 7241], [16676, 16724], [16671, 16719], [12455, 12503], [16675, 16723], [12465, 12513], [16674, 16722], [7196, 7244], [369, 416], [7190, 7238], [7201, 7249], [368, 415], [7194, 7242], [12461, 12509], [428, 954], [7205, 7253], [7192, 7240], [7191, 7239], [12467, 12515], [2509, 2493, 17881], [2477, 2461, 2541], [2493, 17881], [2461, 2541]]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[1942, 1989]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "s: 1942 Type of s: <class 'int'>\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[1989]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "s: 1989 Type of s: <class 'int'>\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n",
      "P[vi] is \n",
      "0\n",
      "and u_ at that value is \n",
      "[]\n",
      "vi is \n",
      "0\n",
      "P is \n",
      "[0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2460 is out of bounds for axis 0 with size 102",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m u, ch \u001b[39m=\u001b[39m h_cluster(X, max_clusters\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[39m# HIERARCHICAL SAMPLING FOR ACTIVE LEARNING\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m xl, z, p, l \u001b[39m=\u001b[39m DH_AL(u, ch, B, t, Y)\n\u001b[0;32m     40\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m********** done ****************\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m train_idx \u001b[39m=\u001b[39m xl[:, \u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)  \u001b[39m# convert to int for indexing\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[57], line 90\u001b[0m, in \u001b[0;36mDH_AL\u001b[1;34m(u, ch, B, T, y)\u001b[0m\n\u001b[0;32m     87\u001b[0m     eu[Au \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     89\u001b[0m     \u001b[39m# Refine pruning & labelling\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m     P, L, XL \u001b[39m=\u001b[39m prune_label(P, u, Au, Lu, ch, z, N, eu, wu)\n\u001b[0;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m XL, np\u001b[39m.\u001b[39marray(z), P, L\n",
      "Cell \u001b[1;32mIn[38], line 46\u001b[0m, in \u001b[0;36mprune_label\u001b[1;34m(P, u, Au, Lu, ch, z, N, eu, wu)\u001b[0m\n\u001b[0;32m     44\u001b[0m chv \u001b[39m=\u001b[39m ch[:, v \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m Pv \u001b[39m=\u001b[39m [v]\n\u001b[1;32m---> 46\u001b[0m Achv \u001b[39m=\u001b[39m [Au[x \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m chv]\n\u001b[0;32m     48\u001b[0m \u001b[39m# While at least one pair of siblings is admissible, refine and label Pv\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mwhile\u001b[39;00m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39msum(Achv) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "Cell \u001b[1;32mIn[38], line 46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     44\u001b[0m chv \u001b[39m=\u001b[39m ch[:, v \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m     45\u001b[0m Pv \u001b[39m=\u001b[39m [v]\n\u001b[1;32m---> 46\u001b[0m Achv \u001b[39m=\u001b[39m [Au[x \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m chv]\n\u001b[0;32m     48\u001b[0m \u001b[39m# While at least one pair of siblings is admissible, refine and label Pv\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[39mwhile\u001b[39;00m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39msum(Achv) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2460 is out of bounds for axis 0 with size 102"
     ]
    }
   ],
   "source": [
    "from predict import predict\n",
    "\n",
    "T = 30  # maximum number of runs (max label budget T*B = 600)\n",
    "B = 20  # batch size\n",
    "reps = 20  # number of repeats for each experiment\n",
    "\n",
    "# For storing error\n",
    "e_rs = []\n",
    "\"\"\"\"\n",
    "for t in range(1, T + 1):\n",
    "    print(f'\\nQUERY BUDGET ------ {t * B}')\n",
    "    acc = []  # accuracy for each repeat\n",
    "    for r in range(reps):\n",
    "        # define the training-set by a random sample from available data\n",
    "        train_idx = sample_indices_covering_all_Y_values(Y, t*B) #np.random.choice(X.shape[0], t * B, replace=False)\n",
    "        x_train = X[train_idx, :]\n",
    "        y_train = Y[train_idx]\n",
    "        print(x_test.shape)\n",
    "        print(y_test.shape)\n",
    "\n",
    "        # CLASSIFICATION\n",
    "        y_pred = predict(x_train, y_train, x_test, 1)\n",
    "        acc.append(np.sum(y_pred == y_test) / len(y_test))\n",
    "\n",
    "    e_rs.append(1 - np.mean(acc))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# CLUSTER BASED ACTIVE LEARNING: the DH learner for an increasing label budget\n",
    "e_al = []\n",
    "for t in range(1, T + 1):\n",
    "    print(f'\\nQUERY BUDGET ------ {t * B}')\n",
    "    acc = []\n",
    "    for r in range(reps):\n",
    "        # INITIAL CLUSTERING\n",
    "        u, ch = h_cluster(X, max_clusters=100)\n",
    "\n",
    "        # HIERARCHICAL SAMPLING FOR ACTIVE LEARNING\n",
    "        xl, z, p, l = DH_AL(u, ch, B, t, Y)\n",
    "        print(\"********** done ****************\")\n",
    "        train_idx = xl[:, 0].astype(int)  # convert to int for indexing\n",
    "        x_train = X[train_idx, :]\n",
    "        y_train = xl[:, 1]\n",
    "\n",
    "        # CLASSIFICATION\n",
    "        y_pred = predict(x_train, y_train, x_test, 1)\n",
    "        acc.append(np.sum(y_pred == y_test) / len(y_test))\n",
    "\n",
    "    e_al.append(1 - np.mean(acc))\n",
    "\n",
    "# PLOT\n",
    "plt.figure(3)\n",
    "plt.plot(np.arange(B, B * T + 1, B), e_rs, '--')\n",
    "plt.plot(np.arange(B, B * T + 1, B), e_al, '--')\n",
    "plt.xlabel('label budget (n)')\n",
    "plt.ylabel('classification error (e)')\n",
    "plt.legend(['passive learning', 'active learning'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b98e3d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d761c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
