{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82a13ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from random import choices, sample\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1081ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_cluster(X, max_clusters=None):\n",
    "    \"\"\"\n",
    "    Builds a hierarchical clustering using the linkage function from scipy \n",
    "    (agglomerative clustering using ward's linkage and euclidean distance).\n",
    "    Records clusters as they merge; output clusters start at the root node.\n",
    "    The two child nodes, associated with each new node, are recorded for reference.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): [N x d] matrix, containing N observations of d-dimensional input data\n",
    "        max_clusters (int, optional): Determines the maximum number of clusters defined. \n",
    "            Default value (N-1) considers clusters down to single observations.\n",
    "\n",
    "    Returns:\n",
    "        list: A list containing N-1 arrays, each represents a node in the hierarchical tree,\n",
    "            containing the data indices associated with each cluster.\n",
    "        np.ndarray: A [2 x N-1] matrix, containing the 2 child nodes for each cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    if max_clusters is None:\n",
    "        max_clusters = len(X) - 1\n",
    "\n",
    "    # Build hierarchical tree\n",
    "    Z = linkage(X, method='ward', metric='euclidean')\n",
    "\n",
    "    N = len(X)\n",
    "    u = [None] * (N - 1)\n",
    "    ch = np.zeros((2, N - 1), dtype=int)\n",
    "\n",
    "    # Using the output of linkage (Z) to build clusters\n",
    "    for m in range(len(u)):\n",
    "        # Join parts p1 & p2 of the clustering together using Z info\n",
    "        if Z[m, 0] <= N:\n",
    "            p1 = [Z[m, 0]]\n",
    "            c1 = int(p1[0])\n",
    "        else:\n",
    "            p1 = u[int(Z[m, 0] - N - 1)]\n",
    "            c1 = 2 * N - int(Z[m, 0])\n",
    "\n",
    "        if Z[m, 1] <= N:\n",
    "            p2 = [Z[m, 1]]\n",
    "            c2 = int(p2[0])\n",
    "        else:\n",
    "            p2 = u[int(Z[m, 1] - N - 1)]\n",
    "            c2 = 2 * N - int(Z[m, 1])\n",
    "\n",
    "        u[m] = p1 + p2\n",
    "        ch[:, m] = [c1, c2]\n",
    "\n",
    "    u = list(reversed(u[:max_clusters]))\n",
    "    ch = np.fliplr(ch[:, :max_clusters])\n",
    "\n",
    "    return u, ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de25ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_label(P, u, Au, Lu, ch, z, N, eu, wu):\n",
    "    \"\"\"\n",
    "    Function to refine the pruning (P) and labelling (L) for the DH active learner.\n",
    "    \n",
    "    Parameters:\n",
    "    - P : list\n",
    "        Input pruning, to be refined (array of node/cluster numbers).\n",
    "    - u : dict\n",
    "        Contains N-1 arrays. Each array represents a node in the hierarchical tree.\n",
    "    - Au : list\n",
    "        Logistic array, indicating the admissibility of each cluster in the current pruning.\n",
    "    - Lu : dict\n",
    "        Cell containing the majority label(s), for each node.\n",
    "    - ch : numpy array\n",
    "        2x(N-1) matrix containing the 2 children nodes for each cluster.\n",
    "    - z : numpy array\n",
    "        Sampled data information array.\n",
    "    - N : int\n",
    "        Total number of clusters.\n",
    "    - eu : list\n",
    "        Error associated with propagating the majority label to unlabelled instances.\n",
    "    - wu : list\n",
    "        Node weights - proportion of the total data in each node.\n",
    "        \n",
    "    Returns:\n",
    "    - P_ : list\n",
    "        Output (refined) pruning.\n",
    "    - L : list\n",
    "        The majority label for each cluster in the refined pruning.\n",
    "    - XL : numpy array\n",
    "        The labelled dataset provided by the DH learner.\n",
    "    \"\"\"\n",
    "    \n",
    "    L = [0] * len(u)  # Initialize admissible cluster label pairs\n",
    "    P_ = list(P)  # Define working pruning\n",
    "\n",
    "    for i, v in enumerate(P):  # For each node in the current pruning\n",
    "        # LABEL parent node in case descendants are not admissible\n",
    "        Lu[1] = 0  # Arbitrary label of root\n",
    "        if len(P) != 1 and len(Lu[v]) == 1:\n",
    "            L[v - 1] = Lu[v]\n",
    "\n",
    "        # Identify first descendants...\n",
    "        chv = ch[:, v - 1]\n",
    "        Pv = [v]\n",
    "        Achv = [Au[x - 1] for x in chv]\n",
    "\n",
    "        # While at least one pair of siblings is admissible, refine and label Pv\n",
    "        while np.sum(np.sum(Achv) == 2) >= 1:\n",
    "            i_ch = [idx for idx, val in enumerate(Achv) if np.sum(val) == 2]\n",
    "\n",
    "            for ich in i_ch:\n",
    "                ep = eu[Pv[ich] - 1]\n",
    "                ech = (1 / np.sum([wu[x - 1] for x in chv[:, ich]])) * np.sum(\n",
    "                    [wu[x - 1] * eu[x - 1] for x in chv[:, ich]])\n",
    "                Lch = [Lu[x] for x in chv[:, ich]]\n",
    "                Lch_log = [len(x) == 1 for x in Lch]\n",
    "\n",
    "                if len(Lu[Pv[ich]]) == 1 and ech < ep and np.sum(Lch_log) == 2:\n",
    "                    Pv[ich] = 0\n",
    "                    u_ = chv[:, ich]\n",
    "                    Pv.extend(list(u_))\n",
    "\n",
    "            Pv = [x for x in Pv if x != 0]\n",
    "\n",
    "            if len(set(Pv)) > chv.shape[1]:\n",
    "                chv = ch[:, [x - 1 for x in Pv]]\n",
    "                Achv = [Au[x - 1] for x in chv.flatten()]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if len(Pv) > 1:\n",
    "            print(f\"\\nTOTAL CLUSTERS {len(P_)}: nodes {Pv} replace node [{v}]\")\n",
    "            P_ = [x for x in P_ if x != v]\n",
    "            P_.extend(Pv)\n",
    "            for uw in Pv:\n",
    "                L[uw - 1] = Lu[uw]\n",
    "\n",
    "    xl = [0] * N\n",
    "    for idx, v in enumerate(P):\n",
    "        if len(P) >= len(set(z[:, -1])):\n",
    "            xi = u[v]\n",
    "            xl[xi[0]] = L[v - 1]\n",
    "\n",
    "    for idx in range(z.shape[0]):\n",
    "        z_ = int(z[idx, 0])\n",
    "        zl = z[idx, -1]\n",
    "        xl[z_ - 1] = zl\n",
    "\n",
    "    XL = np.array([[idx + 1, x] for idx, x in enumerate(xl) if x != 0])\n",
    "\n",
    "    return P_, L, XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a00940e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DH_AL(u, ch, B, T, y):\n",
    "    # Initialize variables\n",
    "    N = len(u[0])\n",
    "    Nu = [len(ue) for ue in u]\n",
    "    wu = np.array(Nu) / N\n",
    "    \n",
    "    z = []\n",
    "    uz = [ [] for _ in range(N-1)]\n",
    "    u_ = u.copy()\n",
    "    \n",
    "    pl = [None] * len(u)\n",
    "    Aul = [None] * len(u)\n",
    "    Au = np.zeros(len(u) + N)\n",
    "    eu = np.ones(len(u) + N)\n",
    "    Lu = [None] * len(u)\n",
    "    \n",
    "    P = [0]\n",
    "    \n",
    "    for t in range(1, T+1):\n",
    "        for b in range(1, B+1):\n",
    "            # Select v from P\n",
    "            prop = wu[P]\n",
    "            for i, v in enumerate(P):\n",
    "                coeff = 1 if len(P) == 1 else 0 if not u_[v] else 1 - max(pl[v][:, -2])\n",
    "                prop[i] *= coeff\n",
    "            \n",
    "            prob = prop / np.sum(prop)\n",
    "            vi = choices(range(len(prob)), prob)[0]\n",
    "            \n",
    "            # Query label\n",
    "            s = sample(u_[P[vi]], 1)[0]\n",
    "            for ui in u_:\n",
    "                if s in ui:\n",
    "                    ui.remove(s)\n",
    "                    \n",
    "            l = y[s]\n",
    "            z.append((s, P[vi], l))\n",
    "            \n",
    "            # Update node counts\n",
    "            u_i = [i for i, ue in enumerate(u) if s in ue]\n",
    "            for uw in u_i:\n",
    "                uz[uw].append((s, l))\n",
    "                nu = len(uz[uw])\n",
    "                \n",
    "                cl, c = zip(*Counter([l for s, l in uz[uw]]).items())\n",
    "                p_l = np.array(c) / nu\n",
    "                \n",
    "                delta = 1 / nu + np.sqrt((p_l * (1 - p_l)) / nu)\n",
    "                lb = np.maximum(p_l - delta, 0)\n",
    "                ub = np.minimum(p_l + delta, 1)\n",
    "                \n",
    "                pl[uw] = np.column_stack((cl, p_l, lb, ub))\n",
    "                Lu[uw] = cl[np.argmax(p_l)]\n",
    "                \n",
    "        # Update admissibilities, error/scores\n",
    "        u_i = [i for i, ple in enumerate(pl) if ple is not None]\n",
    "        for uw in u_i:\n",
    "            beta = 1.5\n",
    "            p_l = pl[uw]\n",
    "            if len(uz[uw]) > 1:\n",
    "                LHS = p_l[:, -2]\n",
    "                RHS = beta * p_l[:, -1] - 1\n",
    "                a_l = LHS[:, None] > RHS\n",
    "                \n",
    "                a_l[np.diag_indices_from(a_l)] = False\n",
    "                idx = np.all(a_l, axis=1)\n",
    "                \n",
    "                Aul[uw] = p_l[idx, 0]\n",
    "                Au[uw] = np.any(idx)\n",
    "                eu[uw] = 1 - np.max(p_l[:, 1]) if np.any(idx) else 1\n",
    "                \n",
    "        eu[Au == 0] = 1\n",
    "        \n",
    "        # Refine pruning & labelling\n",
    "        P, L, XL = prune_label(P, u, Au, Lu, ch, z, N, eu, wu)\n",
    "    \n",
    "    return XL, np.array(z), P, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7fe3de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexample run from https://github.com/labull/EngineeringPatternRecognition/tree/main/matlab/cluster_based_active_learning\\nn = 100;\\nB = 3; % batch size\\nt = n/3; % number of runs\\n\\n% run the DH learner\\n[xl, z] = DH_AL(u, ch, B, t, Y);\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "example run from https://github.com/labull/EngineeringPatternRecognition/tree/main/matlab/cluster_based_active_learning\n",
    "n = 100;\n",
    "B = 3; % batch size\n",
    "t = n/3; % number of runs\n",
    "\n",
    "% run the DH learner\n",
    "[xl, z] = DH_AL(u, ch, B, t, Y);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa508101",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reader import fetch_signals\n",
    "from preprocess import preprocess\n",
    "from feature_extractor import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# gets X_train, y_train or X_test, y_test (pca and std should be None if train=True)\n",
    "def get_train_test(pca = None, scaler = None, train = True):  \n",
    "    print(\"benchmark 0\")  \n",
    "    signals, labels = fetch_signals('C:\\\\Users\\\\amroa\\\\Documents\\\\thesis\\\\data', train = train)\n",
    "    print(\"benchmark 1\")\n",
    "    preprocessed_sig = [preprocess(signal) for signal in signals]\n",
    "    print(\"benchmark 2\")\n",
    "\n",
    "    # extract the characteristics\n",
    "    X_train_time =  np.apply_along_axis(time_domain_characteristics, axis = 1, arr = preprocessed_sig) \n",
    "    print(\"benchmark 3\")\n",
    "    X_train_freq = np.apply_along_axis(frequency_domain_characteristics, axis = 1, arr = preprocessed_sig) \n",
    "    print(\"benchmark 4\")\n",
    "    Y = np.array(labels)\n",
    "\n",
    "    # unstd stands for unstandardized\n",
    "    X_unstd = np.hstack((X_train_time, X_train_freq))\n",
    "    mask_finite = np.isfinite(X_unstd).all(axis=1)\n",
    "    X_unstd = X_unstd[mask_finite]\n",
    "\n",
    "    # standardize the data and reduce dimensionality using PCA\n",
    "    if ((scaler  == None) or (pca == None)):\n",
    "        scaler = StandardScaler()\n",
    "        X_std = scaler.fit_transform(X_unstd)\n",
    "        pca = PCA(n_components=0.9, svd_solver = 'full') \n",
    "        X = pca.fit_transform(X_std)\n",
    "        return X, Y, pca, scaler\n",
    "    else:\n",
    "        X_std = scaler.transform(X_unstd)\n",
    "        X = pca.transform(X_std)\n",
    "        return X, Y, pca, scaler\n",
    "\n",
    "    return None, None, None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3e05c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\amroa\\Documents\\thesis\\preprocess.py:9: RuntimeWarning: invalid value encountered in divide\n",
      "  standard_signal = (signal - mean_signal) / std_signal\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X, Y, pca, scaler = get_train_test()\n",
    "x_test, y_test, _ , _ = get_train_test(pca = pca, scaler = scaler, train = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76d785fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUERY BUDGET ------ 20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     y_train \u001b[39m=\u001b[39m Y[train_idx]\n\u001b[0;32m     19\u001b[0m     \u001b[39m# CLASSIFICATION\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     y_pred \u001b[39m=\u001b[39m predict(x_train, y_train, x_test, \u001b[39m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m     acc\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39msum(y_pred \u001b[39m==\u001b[39m y_test) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y_test))\n\u001b[0;32m     23\u001b[0m e_rs\u001b[39m.\u001b[39mappend(\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mmean(acc))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "from predict import predict\n",
    "\n",
    "T = 30  # maximum number of runs (max label budget T*B = 600)\n",
    "B = 20  # batch size\n",
    "reps = 20  # number of repeats for each experiment\n",
    "\n",
    "# For storing error\n",
    "e_rs = []\n",
    "\n",
    "for t in range(1, T + 1):\n",
    "    print(f'\\nQUERY BUDGET ------ {t * B}')\n",
    "    acc = []  # accuracy for each repeat\n",
    "    for r in range(reps):\n",
    "        # define the training-set by a random sample from available data\n",
    "        train_idx = np.random.choice(X.shape[0], t * B, replace=False)\n",
    "        x_train = X[train_idx, :]\n",
    "        y_train = Y[train_idx]\n",
    "\n",
    "        # CLASSIFICATION\n",
    "        y_pred = predict(x_train, y_train, x_test, 1)\n",
    "        acc.append(np.sum(y_pred == y_test) / len(y_test))\n",
    "\n",
    "    e_rs.append(1 - np.mean(acc))\n",
    "\n",
    "# CLUSTER BASED ACTIVE LEARNING: the DH learner for an increasing label budget\n",
    "e_al = []\n",
    "for t in range(1, T + 1):\n",
    "    print(f'\\nQUERY BUDGET ------ {t * B}')\n",
    "    acc = []\n",
    "    for r in range(reps):\n",
    "        # INITIAL CLUSTERING\n",
    "        u, ch = h_cluster(X, max_clusters=100)\n",
    "\n",
    "        # HIERARCHICAL SAMPLING FOR ACTIVE LEARNING\n",
    "        xl, z, p, l = DH_AL(u, ch, B, t, Y)\n",
    "        train_idx = xl[:, 0].astype(int)  # convert to int for indexing\n",
    "        x_train = X[train_idx, :]\n",
    "        y_train = xl[:, 1]\n",
    "\n",
    "        # CLASSIFICATION\n",
    "        y_pred = predict(x_train, y_train, x_test, 1)\n",
    "        acc.append(np.sum(y_pred == y_test) / len(y_test))\n",
    "\n",
    "    e_al.append(1 - np.mean(acc))\n",
    "\n",
    "# PLOT\n",
    "plt.figure(3)\n",
    "plt.plot(np.arange(B, B * T + 1, B), e_rs, '--')\n",
    "plt.plot(np.arange(B, B * T + 1, B), e_al, '--')\n",
    "plt.xlabel('label budget (n)')\n",
    "plt.ylabel('classification error (e)')\n",
    "plt.legend(['passive learning', 'active learning'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b98e3d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.11.5 (tags/v3.11.5:cce6ba9, Aug 24 2023, 14:38:34) [MSC v.1936 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Python Version:\", sys.version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
